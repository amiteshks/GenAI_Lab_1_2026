{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f95de6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_openai langchain_core langgraph python-dotenv openai\n",
    "# pip install -U langgraph \"langchain[openai]\"\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# 1\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "\n",
    "# --- Shared State ---\n",
    "class LibraryState(TypedDict):\n",
    "    question: str\n",
    "    faq_answer: str\n",
    "    checkout_info: str\n",
    "    final_answer: str\n",
    "#2\n",
    "@traceable(name=\"ClassifierAgent\")\n",
    "def ClassifierAgent(state: LibraryState):\n",
    "    print(\"ClassifierAgent ran\")\n",
    "    print(f\"state: {state}\")\n",
    "\n",
    "    # Build the LLM messages\n",
    "    message_to_llm = [\n",
    "        {\"role\": \"system\", \"content\": '''You are a classifier agent in a library system. Decide if the user is asking about book availability/checkout or about library FAQs. \n",
    "        Reply with JSON containing keys: faq_answer and checkout_info.'''},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {state['question']}\"}\n",
    "    ]\n",
    "\n",
    "    # Call the OpenAI model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=message_to_llm,\n",
    "        temperature=0.2,   # keep it deterministic for classification\n",
    "        max_tokens=150,\n",
    "    )\n",
    "\n",
    "    print (response)\n",
    "    # Extract the content from the response\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    # Ideally, parse as JSON â€” here assuming model returns a dict-like string\n",
    "    try:\n",
    "        import json\n",
    "        parsed = json.loads(answer)\n",
    "        return {\n",
    "            \"faq_answer\": parsed.get(\"faq_answer\", \"\"),\n",
    "            \"checkout_info\": parsed.get(\"checkout_info\", \"\")\n",
    "        }\n",
    "    except Exception:\n",
    "        # fallback if LLM gives plain text\n",
    "        return {\"faq_answer\": answer, \"checkout_info\": \"\"}\n",
    "\n",
    "\n",
    "@traceable(name=\"FAQAgent\")\n",
    "def FAQAgent(state: LibraryState):\n",
    "    print(\"FAQAgent ran\")\n",
    "    print(f\"FAQAgent state\", state)\n",
    "    if not state.get(\"faq_answer\"):\n",
    "        return {\"faq_answer\": \"Default FAQ: Library rules apply\"}\n",
    "    return {}\n",
    "\n",
    "@traceable(name=\"CheckoutAgent\")\n",
    "def CheckoutAgent(state: LibraryState):\n",
    "    print(\"CheckoutAgent ran\")\n",
    "    if not state.get(\"checkout_info\"):\n",
    "        return {\"checkout_info\": \"Checkout info: Not requested\"}\n",
    "    return {}\n",
    "\n",
    "@traceable(name=\"ResponseAgent\")\n",
    "def ResponseAgent(state: LibraryState):\n",
    "    print(\"ResponseAgent ran\")\n",
    "    # final = f\"Q: {state['question']}\\n\"\n",
    "    # if state.get(\"faq_answer\"):\n",
    "    #     final += f\"FAQ: {state['faq_answer']}\\n\"\n",
    "    # if state.get(\"checkout_info\"):\n",
    "    #     final += f\"Checkout: {state['checkout_info']}\"\n",
    "\n",
    "\n",
    "    # Build the LLM messages\n",
    "    message_to_llm = [\n",
    "        {\"role\": \"system\", \"content\": '''You are generating a human friendly response  for a library system based on given data \n",
    "         You will get FAQ_answer and Checkout_info - combine them to give a meningful answer'''},\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {state['question']}, faq_answer: {state['faq_answer']}, checkout_info: {state['checkout_info']}\"}\n",
    "    ]\n",
    "\n",
    "    # Call the OpenAI model\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=message_to_llm,\n",
    "        temperature=0.2,   # keep it deterministic for classification\n",
    "        max_tokens=150,\n",
    "    )\n",
    "\n",
    "    print (response)\n",
    "    # Extract the content from the response\n",
    "    answer = response.choices[0].message.content\n",
    "    return {\"final_answer\": answer}\n",
    "\n",
    "\n",
    "# --- Build the Graph ---\n",
    "builder = StateGraph(LibraryState)\n",
    "builder.add_node(\"ClassifierAgent\", ClassifierAgent)\n",
    "builder.add_node(\"FAQAgent\", FAQAgent)\n",
    "builder.add_node(\"CheckoutAgent\", CheckoutAgent)\n",
    "builder.add_node(\"ResponseAgent\", ResponseAgent)\n",
    "\n",
    "builder.add_edge(START, \"ClassifierAgent\")\n",
    "builder.add_edge(\"ClassifierAgent\", \"FAQAgent\")\n",
    "builder.add_edge(\"ClassifierAgent\", \"CheckoutAgent\")\n",
    "builder.add_edge(\"FAQAgent\", \"ResponseAgent\")\n",
    "builder.add_edge(\"CheckoutAgent\", \"ResponseAgent\")\n",
    "builder.add_edge(\"ResponseAgent\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45969394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               +-----------+              \n",
      "               | __start__ |              \n",
      "               +-----------+              \n",
      "                     *                    \n",
      "                     *                    \n",
      "                     *                    \n",
      "            +-----------------+           \n",
      "            | ClassifierAgent |           \n",
      "            +-----------------+           \n",
      "              ***          **             \n",
      "             *               **           \n",
      "           **                  **         \n",
      "+---------------+           +----------+  \n",
      "| CheckoutAgent |           | FAQAgent |  \n",
      "+---------------+           +----------+  \n",
      "              ***          **             \n",
      "                 *       **               \n",
      "                  **   **                 \n",
      "             +---------------+            \n",
      "             | ResponseAgent |            \n",
      "             +---------------+            \n",
      "                     *                    \n",
      "                     *                    \n",
      "                     *                    \n",
      "                +---------+               \n",
      "                | __end__ |               \n",
      "                +---------+               \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Visualize ---\n",
    "print(graph.get_graph().draw_ascii())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d8aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierAgent ran\n",
      "state: {'question': 'Is The new best seller available? When does library open?'}\n",
      "ChatCompletion(id='chatcmpl-D8IdKz0LuqFx0rgLkxEZaZm3hTuAf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"faq_answer\": \"The library opens at 9 AM and closes at 9 PM from Monday to Saturday, and from 12 PM to 6 PM on Sundays. For specific book availability, please check our online catalog or contact the library directly.\",\\n  \"checkout_info\": \"The new best seller\\'s availability can be checked through our online catalog or at the library\\'s circulation desk.\"\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1770870622, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_de604bd877', usage=CompletionUsage(completion_tokens=81, prompt_tokens=65, total_tokens=146, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "CheckoutAgent ran\n",
      "FAQAgent ran\n",
      "FAQAgent state {'question': 'Is The new best seller available? When does library open?', 'faq_answer': 'The library opens at 9 AM and closes at 9 PM from Monday to Saturday, and from 12 PM to 6 PM on Sundays. For specific book availability, please check our online catalog or contact the library directly.', 'checkout_info': \"The new best seller's availability can be checked through our online catalog or at the library's circulation desk.\"}\n",
      "ResponseAgent ran\n",
      "ChatCompletion(id='chatcmpl-D8IdMgk0nzQAKywPnQHhEp8gRJm9L', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The library opens at 9 AM from Monday to Saturday and from 12 PM to 6 PM on Sundays. To find out if the new best seller is available, you can check our online catalog or visit the library's circulation desk.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1770870624, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_de604bd877', usage=CompletionUsage(completion_tokens=48, prompt_tokens=133, total_tokens=181, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "\n",
      "--- Final Answer ---\n",
      "The library opens at 9 AM from Monday to Saturday and from 12 PM to 6 PM on Sundays. To find out if the new best seller is available, you can check our online catalog or visit the library's circulation desk.\n"
     ]
    }
   ],
   "source": [
    "# --- Run ---\n",
    "result = graph.invoke({\"question\": \"Is The new best seller available? When does library open?\"})\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(result[\"final_answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b69c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = graph.invoke({\"question\": \"Is The Hobbit available?\"})\n",
    "# print(\"\\n--- Final Answer ---\")\n",
    "# print(result[\"final_answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa647a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
